{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataLoader(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        image = torch.unsqueeze(image, 0)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_resize_image(image_path):\n",
    "    image = Image.open(image_path)  \n",
    "    new_size = (144, 144)\n",
    "    resized_image = image.resize(new_size)\n",
    "    preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),                       # Convert the image to a PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize pixel values (mean and std values are common for many pre-trained models)\n",
    "])\n",
    "    return preprocess(resized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feu!\n",
      "feu!\n",
      "feu!\n",
      "feu!\n",
      "feu!\n",
      "feu!\n",
      "feu!\n",
      "feu!\n",
      "feu!\n",
      "feu!\n"
     ]
    }
   ],
   "source": [
    "root_directory = \"dataset_chat/\" \n",
    "subdirectories = [d for d in os.listdir(root_directory) if os.path.isdir(os.path.join(root_directory, d))]\n",
    "\n",
    "train_images = []\n",
    "test_images = []\n",
    "train_labels = []\n",
    "test_labels = []\n",
    "\n",
    "n_classes = 10\n",
    "i = 0\n",
    "for subdirectory in subdirectories[:n_classes]:\n",
    "    print(\"feu!\")\n",
    "    subdirectory_path = os.path.join(root_directory, subdirectory)\n",
    "    jpeg_files = glob.glob(os.path.join(subdirectory_path, \"*.jpg\"))\n",
    "    \n",
    "    label = torch.zeros(n_classes)\n",
    "    label[i] = 1  \n",
    "    \n",
    "\n",
    "    for jpeg_file in jpeg_files[:10]:\n",
    "        tensor_image = load_and_resize_image(jpeg_file)\n",
    "        train_images.append(tensor_image)\n",
    "        train_labels.append(label)\n",
    "    test_images.append(load_and_resize_image(jpeg_files[11]))\n",
    "    test_labels.append(label)\n",
    "    \n",
    "    \n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "learning_rate = 100\n",
    "num_epochs = 5\n",
    "train_dataset = CustomDataLoader(train_images, train_labels)\n",
    "test_dataset = CustomDataLoader(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.model = models.resnet18(pretrained=True, progress=False)     \n",
    "        \n",
    "               \n",
    "        dim_before_fc = self.model.fc.in_features\n",
    "        print(dim_before_fc)\n",
    "        self.model.fc = nn.Linear(dim_before_fc, 10)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x =  self.model(x)\n",
    "        return self.sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, test_dataset, epoch, num_epochs):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_dataset:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            print(predicted)\n",
    "            print(labels)\n",
    "            for i in range(len(labels)):\n",
    "                if predicted == np.argmax(labels):\n",
    "                    correct += 1\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "0\n",
      "Epoch [1/5], Test Accuracy: 10.00%\n",
      "1\n",
      "Epoch [2/5], Test Accuracy: 10.00%\n",
      "2\n",
      "Epoch [3/5], Test Accuracy: 10.00%\n",
      "3\n",
      "Epoch [4/5], Test Accuracy: 10.00%\n",
      "4\n",
      "Epoch [5/5], Test Accuracy: 10.00%\n",
      "Training and evaluation finished.\n"
     ]
    }
   ],
   "source": [
    "model = SimpleCNN(n_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(epoch)\n",
    "    for images, labels in train_dataset:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)[0]\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    eval_model(model, test_dataset, epoch, num_epochs)\n",
    "\n",
    "\n",
    "print('Training and evaluation finished.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([0])\n",
      "tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([0])\n",
      "tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([0])\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([0])\n",
      "tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "tensor([0])\n",
      "tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
      "tensor([0])\n",
      "tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "tensor([0])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
      "tensor([0])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
      "tensor([0])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "Epoch [1/0], Test Accuracy: 10.00%\n"
     ]
    }
   ],
   "source": [
    "eval_model(model, test_dataset, 0, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CatProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
